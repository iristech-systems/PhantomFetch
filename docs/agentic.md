# Building AI Scrapers

PhantomFetch is designed from the ground up to be **AI-Native**. Unlike traditional libraries that require writing imperative Python code for every step (e.g., `await page.click(...)`), PhantomFetch exposes a **JSON-serializable Action Schema**.

## The Data-Driven Philosophy

Why use declarative actions instead of raw code?

1.  **Safety**: You can safely execute an action plan generated by an LLM without using `exec()` or `eval()`.
2.  **Portability**: Scraping logic becomes data (JSON), which can be stored in a database, sent over an API, or effectively cached.
3.  **Resilience**: The engine handles retries, waits, and race conditions automatically, so the AI doesn't have to "know" about `asyncio.sleep`.

## Integration with LLMs

A typical Agentic Workflow using PhantomFetch looks like this:

### 1. The Prompt
You tell your LLM (Claude, GPT-4) about the available `Action` schema.

> **System Prompt**:
> You are a scraping assistant. Output a JSON list of actions to perform.
> Available actions: `goto`, `click`, `input`, `extract`, `wait`.
>
> **User**:
> "Go to google.com, search for 'latest ai news', and extract the top headlines."

### 2. The Generation
The LLM generates a robust JSON plan:

```json
[
  { "action": "input", "selector": "textarea[name='q']", "value": "latest ai news" },
  { "action": "click", "selector": "input[type='submit']" },
  { "action": "wait", "selector": "#search" },
  {
    "action": "extract",
    "selector": "#search .g",
    "schema": {
      "title": "h3 :: text",
      "link": "a :: attr(href)"
    }
  }
]
```

### 3. The Execution
You feed this directly into PhantomFetch:

```python
import json
from phantomfetch import Fetcher, Action

# Assume 'llm_response' contains the string above
plan = json.loads(llm_response)
actions = [Action(**a) for a in plan]

async with Fetcher() as fetcher:
    # PhantomFetch executes the plan faithfully
    response = await fetcher.fetch("https://google.com", actions=actions)
    print(response.action_results[-1].data) # Your data!
```

## Advanced Patterns

### Conditional AI Logic (`if`)
Sometimes the AI suspects a popup might appear. It can use the `if` action:

```json
{
  "action": "if",
  "selector": ".newsletter-popup",
  "then_actions": [
    { "action": "click", "selector": ".newsletter-popup .close-btn" }
  ]
}
```

### Visual Validation
Combine `screenshot` actions with a Vision Model (e.g., GPT-4o) to verify state:

1.  **Action**: `{ "action": "screenshot" }`
2.  **Process**: Send screenshot to Vision Model -> "Did the login succeed?"
3.  **React**: If no, generate a new plan to handle the error.

## Best Practices

*   **Feed the Schema**: Include the `Action` TypedDict or Pydantic definition in your LLM's system prompt context.
*   **Use `fail_on_error`**: Generally set `fail_on_error=True` for AI agents so they receive immediate feedback if a step (like a selector) fails, allowing them to retry with a different strategy.
*   **Selector Builder**: Use the **Interactive Selector Builder** tool to help the AI discover robust selectors during a "Recon" phase before locking in a production plan.
